{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Scalable Machine Learning Applications "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create your environment with Google Cloud\n",
    "2. Serve a Deep Learning model as an API using Keras, Flask, and Docker\n",
    "3. Deploy said model with Kubernetes\n",
    "4. Bask in the glory of your newfound knowledge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create an Environment with Google Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a virtual Machine on GCP\n",
    "\n",
    "The next step is to select the compute size we want to use. <br> The default (read: cheapest) should work just fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/800/1*nUAYU6Ol3kc-BJF5gZ4_RA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start a Google Cloud VM, open up the ribbon on the left side of your screen. <br> \n",
    "Theb Select ``Compute Engine``.<br>\n",
    "Then choose “Create Instance”. <br>\n",
    "You can see in the photo below that I have one instance already running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://cdn-images-1.medium.com/max/800/1*1cx80c0CgohQRvIYmkck9w.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to select the compute size we want to use. The default (read: cheapest) settings should work just fine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://cdn-images-1.medium.com/max/800/1*TlybZKutOgD2xF4_vDt8rA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I choose the operating system and disk space I want to use. Select “Boot Disk” to edit the defaults. I choose Centos 7 for my operating system and increase the amount of disk from 10GB to 100GB. My choice of operating system (Centos) is not required. I would recommend increasing the disk size beyond 10GBs, however, as the Docker containers we create are ~1GB each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step before we create the VM is to set our Firewall rules to allow HTTP/S. Full transparency, I’m not sure if this step is required. I will show you how to edit the firewall settings to test our API on the VM before we deploy it to Kubernetes. So checking these boxes is not sufficient — there is more work to be done. I just haven’t gone back to try this tutorial again without checking them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://cdn-images-1.medium.com/max/800/1*97xCXpVyFMnrk6k1m5ympQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now click “Create”. Bravo! The hard part is basically done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://cdn-images-1.medium.com/max/800/1*b80mKfRZXXbvWf77gwZX3Q.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step - 2 Install Docker into your VM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s SSH into our VM and install Docker. \n",
    "<br>The easiest way to do this is to simply click the SSH icon next to your VM (below).\n",
    "<br>This opens a terminal in your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://cdn-images-1.medium.com/max/800/1*qRWFVHOiL5HJHWsXfSPMeQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be able to see a terminal window open in a new tab as below:\n",
    "\n",
    "![image](https://github.com/BenjaminAkera/Talks/raw/master/res/init_terminal.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Remove the existing version of Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "sudo yum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-selinux docker-engine-selinux docker-engine\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Install latest version of Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "sudo yum install -y yum-utils device-mapper-persistent-data lvm2\n",
    "sudo yum-config-manager \\\n",
    "    --add-repo \\\n",
    "    https://download.docker.com/linux/centos/docker-ce.repo\n",
    "sudo yum install docker-ce\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Start Docker and Run Test Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "sudo systemctl start docker\n",
    "sudo docker run hello-world\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Expected Output:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://github.com/BenjaminAkera/Talks/raw/master/res/hello_docker.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Create your Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step consists of 3 parts:\n",
    "Creating a machine learning model can be done in two ways: \n",
    "    1. You can build a model from scratch and train it eg: Regression/classification\n",
    "    2. Use a pretrained model for transfer learning.\n",
    "    \n",
    "In this case we shall use a pre-trained model for inference.<br>\n",
    "We shall use the <b>Resnet</b> Image classification model pretrained on ImageNet\n",
    "\n",
    "### Convolutional Neural Network Model\n",
    "![image](https://github.com/BenjaminAkera/Talks/raw/master/res/convnet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Serve the Resnet Pre-trained Model with Flask "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we create a flask web application that serves the pretrianed tensorflow model.<br>\n",
    "The model has already been trained on ImageNet and can classify 1000 classes of everyday objects<br>\n",
    "We use the Keras wrapper over tensorflow to load the model file and pass it to helper functions to sanitize the inputs\n",
    "\n",
    "Create the directory where your project will reside: ```mkdir keras-app```<br>\n",
    "change directory into the new directory:  ```cd keras-app``` <br>\n",
    "create a new file with nano ```nano app.py```<br>\n",
    "\n",
    "Copy the code in the cell below and save it as ``app.py``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "# USAGE\n",
    "# Start the server:\n",
    "# \tpython app.py\n",
    "# Submit a request via cURL:\n",
    "# \tcurl -X POST -F image=@dog.jpg 'http://localhost:5000/predict'\n",
    "\n",
    "# import the necessary packages\n",
    "from keras.applications import ResNet50\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications import imagenet_utils\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import flask\n",
    "import io\n",
    "import tensorflow as tf\n",
    "\n",
    "# initialize our Flask application and the Keras model\n",
    "app = flask.Flask(__name__)\n",
    "model = None\n",
    "\n",
    "def load_model():\n",
    "\t# load the pre-trained Keras model (here we are using a model\n",
    "\t# pre-trained on ImageNet and provided by Keras, but you can\n",
    "\t# substitute in your own networks just as easily)\n",
    "\tglobal model\n",
    "\tmodel = ResNet50(weights=\"imagenet\")\n",
    "\tglobal graph\n",
    "\tgraph = tf.get_default_graph()\n",
    "\n",
    "def prepare_image(image, target):\n",
    "\t# if the image mode is not RGB, convert it\n",
    "\tif image.mode != \"RGB\":\n",
    "\t\timage = image.convert(\"RGB\")\n",
    "\n",
    "\t# resize the input image and preprocess it\n",
    "\timage = image.resize(target)\n",
    "\timage = img_to_array(image)\n",
    "\timage = np.expand_dims(image, axis=0)\n",
    "\timage = imagenet_utils.preprocess_input(image)\n",
    "\n",
    "\t# return the processed image\n",
    "\treturn image\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "\t# initialize the data dictionary that will be returned from the\n",
    "\t# view\n",
    "\tdata = {\"success\": False}\n",
    "\n",
    "\t# ensure an image was properly uploaded to our endpoint\n",
    "\tif flask.request.method == \"POST\":\n",
    "\t\tif flask.request.files.get(\"image\"):\n",
    "\t\t\t# read the image in PIL format\n",
    "\t\t\timage = flask.request.files[\"image\"].read()\n",
    "\t\t\timage = Image.open(io.BytesIO(image))\n",
    "\n",
    "\t\t\t# preprocess the image and prepare it for classification\n",
    "\t\t\timage = prepare_image(image, target=(224, 224))\n",
    "\n",
    "\t\t\t# classify the input image and then initialize the list\n",
    "\t\t\t# of predictions to return to the client\n",
    "\t\t\twith graph.as_default():\n",
    "\t\t\t\tpreds = model.predict(image)\n",
    "\t\t\t\tresults = imagenet_utils.decode_predictions(preds)\n",
    "\t\t\t\tdata[\"predictions\"] = []\n",
    "\n",
    "\t\t\t\t# loop over the results and add them to the list of\n",
    "\t\t\t\t# returned predictions\n",
    "\t\t\t\tfor (imagenetID, label, prob) in results[0]:\n",
    "\t\t\t\t\tr = {\"label\": label, \"probability\": float(prob)}\n",
    "\t\t\t\t\tdata[\"predictions\"].append(r)\n",
    "\n",
    "\t\t\t\t# indicate that the request was a success\n",
    "\t\t\t\tdata[\"success\"] = True\n",
    "\n",
    "\t# return the data dictionary as a JSON response\n",
    "\treturn flask.jsonify(data)\n",
    "\n",
    "# if this is the main thread of execution first load the model and\n",
    "# then start the server\n",
    "if __name__ == \"__main__\":\n",
    "\tprint((\"* Loading Keras model and Flask starting server...\"\n",
    "\t\t\"please wait until server has fully started\"))\n",
    "\tload_model()\n",
    "\tapp.run(host='0.0.0.0')\n",
    "       \n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 -  Dockerize the Flask Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Create a ```requirements.txt``` file that we can use to define the dependencies used by the flask application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Create a Requirements.txt File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in your terminal type: ``` nano requirements.txt``` and paste the contents below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "keras\n",
    "tensorflow\n",
    "flask\n",
    "gevent\n",
    "pillow\n",
    "requests\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the text file in nano by pressing ``ctrl+O`` then ``ctrl+z`` to exit nano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Create a Docker File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type in terminal: ``` touch Dockerfile ``` \n",
    "open the newly created ``Dockerfile`` with nano ie. ```nano Dockerfile```<br>\n",
    "copy and paste the contents below and save the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "FROM python:3.6\n",
    "WORKDIR /app\n",
    "COPY requirements.txt /app\n",
    "RUN pip install -r ./requirements.txt\n",
    "COPY app.py /app\n",
    "CMD [\"python\", \"app.py\"]~\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line1: instructing docker to download the base image of Python3 <br>\n",
    "Line2: use the Python package manager pip to install the packages detailed in ```requirements.txt``` <br>\n",
    "Line3: we then tell Docker to run our script via ```python app.py```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. Build the Docker Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sudo docker build -t keras-app:latest .```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instructs Docker to build a container for the code located in our current working directory keras-app\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv. Run the Docker Container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sudo docker run -d -p 5000:5000 keras-app```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick note about the numbers, 5000:5000 — here we are telling Docker to make port 5000 externally available and to forward our local app to that port (which is also running on port 5000 locally)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check status of our container by running:<br> ```sudo docker ps -a```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Output:</b>\n",
    "    \n",
    "```\n",
    "CONTAINER ID          IMAGE               COMMAND             CREATED             STATUS                PORTS              NAMES\n",
    "d82f65802166        keras-app           \"python app.py\"     About an hour ago   Up About an hour          0.0.0.0:5000->5000/tcp   nervous_northcutt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v. Test our model locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our model running, now it is time to test it. <br>\n",
    "This model accepts as input a photo of a dog and returns the dog’s breed. \n",
    "\n",
    "Download the image of a dog (or any animal) and save it in your working directory. <br> You can use wget ie: ```Wget https://github.com/jrosebr1/simple-keras-rest-api/raw/master/dog.jpg```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://cdn-images-1.medium.com/max/800/1*FJWlc5VIb2k5Y64DgMZuww.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Terminal Run:\n",
    "    \n",
    "```curl -X POST -F image=@dog.jpg 'http://localhost:5000/predict'```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that “dog.jpg” is in your current directory (or provide the appropriate path to the file).\n",
    "\n",
    "You should see a result  Like:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n",
    "{\"predictions\":[{\"label\":\"beagle\",\"probability\":0.987775444984436},{\"label\":\"pot\",\"probability\":0.0020967808086425066},{\"label\":\"Cardigan\",\"probability\":0.001351703773252666},{\"label\":\"Walker_hound\",\"probability\":0.0012711131712421775},{\"label\":\"Brittany_spaniel\",\"probability\":0.0010085132671520114}],\"success\":true}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 - Deploy Model to Kubernettes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1. Create a docker hub account (if you dont have one)</b>\n",
    "\n",
    "The first thing we do is upload our model to Docker Hub. (If you don’t have a Docker Hub account, create one now — don’t worry, it’s free).<br> The reason we do this is that we won’t physically move our container to our Kubernetes cluster.<br>\n",
    "Instead, we will instruct Kubernetes to install our container from a centrally hosted server, i.e., **Docker Hub**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2. Login to your Docker Hub account</b>\n",
    "\n",
    "Once you have created your Docker Hub account, log in from the command line via ```sudo docker login```. <br>\n",
    "You’ll need to supply your username and password just as if you were logging into the website.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see a message like this:\n",
    "\n",
    " \n",
    "```Login Succeeded```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you were able to login successfully. Now let’s move to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3. Tag your container</b>\n",
    "\n",
    "We need to tag our container before we can upload it. <br>\n",
    "Think of this step as giving our container a name.<br>\n",
    "First, run ```sudo docker images``` and locate the image id for our keras-app container.<br>\n",
    "The output should look something like this:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ```bash\n",
    " REPOSITORY   TAG     IMAGE ID     CREATED       SIZE \n",
    " keras-app    latest  d1ae332f45cb About an hour ago   1.61GB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s tag our keras-app. Be sure to follow my formatting and replace the values for image id and docker hub id with your specific values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```bash\n",
    "#Format\n",
    "sudo docker tag <your image id> <your docker hub id>/<app name>\n",
    "#My Exact Command - Make Sure To Use Your Inputs\n",
    "sudo docker tag d1ae332f45cb akeraben/keras-app\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>4. Push our container to Docker Hub</b>\n",
    "\n",
    "Now we can push our container. From the shell run:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash \n",
    "#Format\n",
    "sudo docker push <your docker hub name>/<app-name>\n",
    "#My exact command\n",
    "sudo docker push akeraben/keras-app\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if you navigate back to Docker Hub’s website, you should see your ``keras-app`` repository. \n",
    "<br>Well done! We’re ready for the final stretch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>5. Create a Kubernetes Cluster</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "From the Google Cloud home screen, select **Kubernetes Engine**\n",
    "\n",
    "\n",
    "Next we’ll customize the size of the nodes in our cluster. <br>\n",
    "I’ll select **4vCPUs with 15 GBs of RAM**. You can try this with a smaller cluster.<br>\n",
    "Remember, the default settings spin up **3 nodes**, so your cluster will have **3X** the resources of what your provision, i.e., in my case 45 GBs of Ram.<br>\n",
    "I’m being a bit lazy and choosing a larger size as we won’t have our kubernetes cluster running for very long.\n",
    "\n",
    "\n",
    "After that, just click **Create**. It will take a minute or two for you cluster to spin up.<br>\n",
    "Now let’s connect to the cluster. Click **Run** in Cloud Shell to bring up the console for the Kubernetes cluster.\n",
    "\n",
    "Note that this is a separate shell environment from your VM where you created and tested your Docker container. We could install Kubernetes on VMs, but Google’s Kubernetes service automates that for us.\n",
    "Now we run our docker container in Kubernetes. <br>\n",
    "Note that the image tag is just pointing to our hosted docker image on Docker Hub.\n",
    "\n",
    "In addition, we’ll specify with --port that we want to run our app on **port 5000**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```kubectl run keras-app --image=gcav66/keras-app --port 5000```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Kubernetes, containers all run inside of pods. <br>\n",
    "We can verify that our pod is running by typing kubectl get pods.\n",
    "If you see something like this below, you’re all set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash \n",
    "akeraben@cloudshell:~ (basic-web-app-test)$ kubectl get pods\n",
    "NAME                         READY     STATUS    RESTARTS   AGE\n",
    "keras-app-79568b5f57-5qxqk   1/1       Running   0          1m\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our pod is alive and running, we need to expose our pod on port 80 to the outside world. <br>This means that anyone visiting the IP address of our deployment can access our API. <br>It also means we don’t have to specify a pesky port number after our url like we did before (say goodbye to :5000).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```kubectl expose deployment keras-app --type=LoadBalancer --port 80 --target-port 5000```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’re almost there! Now, we determine the status of our deployment (and the URL that we need to call our API) by running kubectl get service . Again, if the output of that command looks like what I have below, you’re doing great.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "akeraben@cloudshell:~ (basic-web-app-test)$ kubectl get service\n",
    "NAME         TYPE           CLUSTER-IP     EXTERNAL-IP     PORT(S)        AGE\n",
    "keras-app    LoadBalancer   10.11.250.71   35.225.226.94   80:30271/TCP   4m\n",
    "kubernetes   ClusterIP      10.11.240.1    <none>          443/TCP        18m\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab that cluster-ip for your keras application because now is the moment of truth. Open your local terminal (or wherever you have dog photo handy) and run the following command to call the API \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "```curl -X POST -F image=@dog.jpg 'http://<your service IP>/predict'```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feast your eyes on the results!\n",
    "As you can see below, the API correctly returns the label of beagle for the picture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```$ curl -X POST -F image=@dog.jpg 'http://35.225.226.94/predict'```\n",
    "\n",
    "**output**\n",
    "\n",
    "```json\n",
    "{\"predictions\":[{\"label\":\"beagle\",\"probability\":0.987775444984436},{\"label\":\"pot\",\"probability\":0.0020967808086425066},{\"label\":\"Cardigan\",\"probability\":0.001351703773252666},{\"label\":\"Walker_hound\",\"probability\":0.0012711131712421775},{\"label\":\"Brittany_spaniel\",\"probability\":0.0010085132671520114}],\"success\":true}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, there are many improvements we could make to this project.<li>We should change the python web server running our flask app from our local python server to something production-grade like **gunicorn/uWSGI**</li><li>We should also explore the scaling and management features of Kubernetes, which we barely touched on. </li><li>Finally, we might try building a kubernetes environment from scratch.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspiration came from the Following awesome resources\n",
    "<li> <a href=\"https://medium.com/analytics-vidhya/deploy-your-first-deep-learning-model-on-kubernetes-with-python-keras-flask-and-docker-575dc07d9e76\">This Blog</a></li>\n",
    "<li> <a href=\"https://www.youtube.com/watch?v=1lgsQ3PKz9M\">This Video By Siraj Raval</a></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Resources on Kubernettes & ML in Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><a href=\"https://kubernetes.io\">Kubernettes Documentation</a></li> \n",
    "<li><a href=\"https://thenewstack.io/use-kubernetes-to-speed-machine-learning-development/\">Use Kubernetes to Speed Machine Learning Development</a> </li>\n",
    "<li><a href=\"https://www.infoq.com/news/2018/04/booking-kubernetes-machine-learn\">How Booking.com Uses Kubernetes for Machine Learning</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
